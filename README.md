# ðŸŒ½ Machine Learning Pipeline for Vomitoxin Prediction

This repository contains a **machine learning pipeline** for predicting **vomitoxin levels in corn** using spectral data. The project covers **data preprocessing, model training, evaluation, and API deployment**.

---

## ðŸ“Œ 1. Project Structure  
```
ML_Assignment/
â”‚â”€â”€ ML_ASSIGNMENT.ipynb        # Jupyter Notebook with entire pipeline
â”‚â”€â”€ app.py                     # Flask API for model predictions
â”‚â”€â”€ test_api.py                 # Script to test the API
â”‚â”€â”€ spectral_model.pkl         # Trained ML model file
â”‚â”€â”€ datasets/                  # Folder containing datasets
â”‚   â”œâ”€â”€ original_dataset.csv
â”‚   â”œâ”€â”€ preprocessed_dataset.csv
â”‚   â”œâ”€â”€ actual_vs_predicted.csv
â”‚â”€â”€ README.md                   # Setup instructions (this file)
â”‚â”€â”€ requirements.txt             # List of dependencies
â””â”€â”€ .gitignore                   # Ignore unnecessary files
```

---

## ðŸ“Œ 2. Setup Instructions  
### ðŸ”¹ Step 1: Clone the Repository  
```sh
git clone https://github.com/YOUR_USERNAME/ML_Assignment.git
cd ML_Assignment
```

### ðŸ”¹ Step 2: Create a Virtual Environment (Optional)  
```sh
python -m venv venv
source venv/bin/activate   # On macOS/Linux
venv\Scripts\activate      # On Windows
```

### ðŸ”¹ Step 3: Install Dependencies  
```sh
pip install -r requirements.txt
```
---

## ðŸ“Œ 3. Running the Code  
### ðŸ”¹ Open and Run the Jupyter Notebook  
- Open `ML_ASSIGNMENT.ipynb` in Jupyter Notebook or VS Code.  
- Run all cells to see **data preprocessing, model training, and evaluation**.

---

## ðŸ“Œ 4. Running the Flask API  
### ðŸ”¹ Start the API Server  
```sh
python app.py
```
âœ… If the API runs successfully, it will show:  
```
 * Running on http://127.0.0.1:5000/
```

### ðŸ”¹ Test the API Using Python (`test_api.py`)  
```python
import requests

url = "http://127.0.0.1:5000/predict"
data = {str(i): [0.5] for i in range(453)}  # 453 feature values

response = requests.post(url, json=data)
print(response.json())  # Model predictions
```

### ðŸ”¹ Test the API Using Postman  
1. **Set request type to** `POST`  
2. **Enter URL:** `http://127.0.0.1:5000/predict`  
3. **Go to "Body" â†’ raw â†’ JSON** and input:
   ```json
   {
       "0": [0.5], "1": [0.5], "2": [0.5]
   }
   ```
4. **Click "Send"** â†’ You should see predictions.

---

## ðŸ“Œ 5. Datasets  
- **Original Dataset:** `datasets/original_dataset.csv` (Raw data before preprocessing)  
- **Preprocessed Dataset:** `datasets/preprocessed_dataset.csv` (Cleaned & transformed data)  
- **Actual vs. Predicted:** `datasets/actual_vs_predicted.csv` (Model performance evaluation)  

---

## ðŸ“Œ 6. Model Training & Evaluation  
- The model was trained using **XGBoost** and evaluated using:  
  - **Mean Absolute Error (MAE):** 6.51  
  - **Mean Squared Error (MSE):** 378.18  
  - **RÂ² Score:** 0.9999  
- The trained model is saved as `spectral_model.pkl`.  

---

## ðŸ“Œ 7. Deployment (Optional)  
To deploy the model via **Flask API**:
```sh
python app.py
```
For **Docker deployment**:
```sh
docker build -t ml-assignment .
docker run -p 5000:5000 ml-assignment
```
This will make the API accessible at `http://127.0.0.1:5000/predict`.

---

## ðŸ“Œ 8. Key Findings & Future Improvements  
- âœ… **High prediction accuracy (RÂ² Score: 0.9999)**  
- âœ… **Feature selection & log transformation improved performance**  
- ðŸ”¹ **Future improvements:** Deploy to cloud (AWS/GCP), interpretability with SHAP/LIME  

---

